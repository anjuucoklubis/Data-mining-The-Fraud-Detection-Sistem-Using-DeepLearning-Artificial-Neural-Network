{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yaDXB7ow0KWE"
   },
   "source": [
    "# Proyek Mata Kuliah Data Mining\n",
    "# Kelompok 8\n",
    "- 12S19011 Kevin Anju Sona Manurung\n",
    "- 12S19028 Anju Ucok Lubis\n",
    "- 12S19050 Yemima Febe Yanti Marpaung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljrxg00k0O8Z"
   },
   "source": [
    "## 1. Load Dataset *fraud_detection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SoT3M5cLya7n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualisasi\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "#Tools (keras backend tensorflow)\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#Metrics sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraud_detection_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from numpy.core.defchararray import add\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('dx2_koo_k93', axis=1)\n",
    "df = df.drop('dx2_u00_u99', axis=1)\n",
    "df = df.drop('procv00_v89', axis=1)\n",
    "df.drop('visit_id', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iml6M6EH5sGr"
   },
   "outputs": [],
   "source": [
    "df['jkpst'].replace(to_replace = ['L', 'P'], value = [0, 1], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wpLunlqNaEK"
   },
   "source": [
    "Lakukan transformasi data ke semua nilai yang bernilai object agar bernilai numerik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4bHQqKeC6GkD"
   },
   "outputs": [],
   "source": [
    "data_categorical = df.select_dtypes(include=['object']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rRJtsDIXNbjO",
    "outputId": "a467afd0-f418-4a02-e130-af77aee29c3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typeppk</th>\n",
       "      <th>cmg</th>\n",
       "      <th>diagprimer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SB</td>\n",
       "      <td>F</td>\n",
       "      <td>f00_f99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>e00_e90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>Q</td>\n",
       "      <td>r00_r99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SC</td>\n",
       "      <td>Q</td>\n",
       "      <td>r00_r99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>f00_f99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  typeppk cmg diagprimer\n",
       "0      SB   F    f00_f99\n",
       "1      C    E    e00_e90\n",
       "2      B    Q    r00_r99\n",
       "3      SC   Q    r00_r99\n",
       "4      B    F    f00_f99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x3maVGcNNdHi"
   },
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skAzCBwqNfSe",
    "outputId": "52d3b484-db1d-45fb-90f1-588d59c0ecb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anjuu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\anjuu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\anjuu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\anjuu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "df['typeppk'] = lbl_enc.fit_transform(df[['typeppk']])\n",
    "df['jkpst'] = lbl_enc.fit_transform(df[['jkpst']])\n",
    "df['cmg'] = lbl_enc.fit_transform(df[['cmg']])\n",
    "df['diagprimer'] = lbl_enc.fit_transform(df[['diagprimer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_Li01WXNiVU",
    "outputId": "73b12b18-de0a-4bfe-ef52-30681ba643bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200217 entries, 0 to 200216\n",
      "Data columns (total 49 columns):\n",
      " #   Column         Non-Null Count   Dtype\n",
      "---  ------         --------------   -----\n",
      " 0   kdkc           200217 non-null  int64\n",
      " 1   dati2          200217 non-null  int64\n",
      " 2   typeppk        200217 non-null  int32\n",
      " 3   jkpst          200217 non-null  int64\n",
      " 4   umur           200217 non-null  int64\n",
      " 5   jnspelsep      200217 non-null  int64\n",
      " 6   los            200217 non-null  int64\n",
      " 7   cmg            200217 non-null  int32\n",
      " 8   severitylevel  200217 non-null  int64\n",
      " 9   diagprimer     200217 non-null  int32\n",
      " 10  dx2_a00_b99    200217 non-null  int64\n",
      " 11  dx2_c00_d48    200217 non-null  int64\n",
      " 12  dx2_d50_d89    200217 non-null  int64\n",
      " 13  dx2_e00_e90    200217 non-null  int64\n",
      " 14  dx2_f00_f99    200217 non-null  int64\n",
      " 15  dx2_g00_g99    200217 non-null  int64\n",
      " 16  dx2_h00_h59    200217 non-null  int64\n",
      " 17  dx2_h60_h95    200217 non-null  int64\n",
      " 18  dx2_i00_i99    200217 non-null  int64\n",
      " 19  dx2_j00_j99    200217 non-null  int64\n",
      " 20  dx2_l00_l99    200217 non-null  int64\n",
      " 21  dx2_m00_m99    200217 non-null  int64\n",
      " 22  dx2_n00_n99    200217 non-null  int64\n",
      " 23  dx2_o00_o99    200217 non-null  int64\n",
      " 24  dx2_p00_p96    200217 non-null  int64\n",
      " 25  dx2_q00_q99    200217 non-null  int64\n",
      " 26  dx2_r00_r99    200217 non-null  int64\n",
      " 27  dx2_s00_t98    200217 non-null  int64\n",
      " 28  dx2_v01_y98    200217 non-null  int64\n",
      " 29  dx2_z00_z99    200217 non-null  int64\n",
      " 30  proc00_13      200217 non-null  int64\n",
      " 31  proc14_23      200217 non-null  int64\n",
      " 32  proc24_27      200217 non-null  int64\n",
      " 33  proc28_28      200217 non-null  int64\n",
      " 34  proc29_31      200217 non-null  int64\n",
      " 35  proc_32_38     200217 non-null  int64\n",
      " 36  proc39_45      200217 non-null  int64\n",
      " 37  proc46_51      200217 non-null  int64\n",
      " 38  proc52_57      200217 non-null  int64\n",
      " 39  proc58_62      200217 non-null  int64\n",
      " 40  proc63_67      200217 non-null  int64\n",
      " 41  proc68_70      200217 non-null  int64\n",
      " 42  proc71_73      200217 non-null  int64\n",
      " 43  proc74_75      200217 non-null  int64\n",
      " 44  proc76_77      200217 non-null  int64\n",
      " 45  proc78_79      200217 non-null  int64\n",
      " 46  proc80_99      200217 non-null  int64\n",
      " 47  proce00_e99    200217 non-null  int64\n",
      " 48  label          200217 non-null  int64\n",
      "dtypes: int32(3), int64(46)\n",
      "memory usage: 72.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Z44_G0RGNj8c",
    "outputId": "7080c52c-26c6-450f-c3cc-3ee83a09ebe1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kdkc</th>\n",
       "      <th>dati2</th>\n",
       "      <th>typeppk</th>\n",
       "      <th>jkpst</th>\n",
       "      <th>umur</th>\n",
       "      <th>jnspelsep</th>\n",
       "      <th>los</th>\n",
       "      <th>cmg</th>\n",
       "      <th>severitylevel</th>\n",
       "      <th>diagprimer</th>\n",
       "      <th>...</th>\n",
       "      <th>proc58_62</th>\n",
       "      <th>proc63_67</th>\n",
       "      <th>proc68_70</th>\n",
       "      <th>proc71_73</th>\n",
       "      <th>proc74_75</th>\n",
       "      <th>proc76_77</th>\n",
       "      <th>proc78_79</th>\n",
       "      <th>proc80_99</th>\n",
       "      <th>proce00_e99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1107</td>\n",
       "      <td>150</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1303</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1114</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601</td>\n",
       "      <td>90</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1006</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   kdkc  dati2  typeppk  jkpst  umur  jnspelsep  los  cmg  severitylevel  \\\n",
       "0  1107    150       22      1    64          2    0    5              0   \n",
       "1  1303    200        2      0    45          1    9    4              3   \n",
       "2  1114    172        1      1    34          2    0   16              0   \n",
       "3   601     90       23      0    34          2    0   16              0   \n",
       "4  1006    130        1      0    27          2    0    5              0   \n",
       "\n",
       "   diagprimer  ...  proc58_62  proc63_67  proc68_70  proc71_73  proc74_75  \\\n",
       "0           4  ...          0          0          0          0          0   \n",
       "1           3  ...          0          0          0          0          0   \n",
       "2          17  ...          0          0          0          0          0   \n",
       "3          17  ...          0          0          0          0          0   \n",
       "4           4  ...          0          0          0          0          0   \n",
       "\n",
       "   proc76_77  proc78_79  proc80_99  proce00_e99  label  \n",
       "0          0          0          0            0      1  \n",
       "1          0          0          4            0      1  \n",
       "2          0          0          0            0      1  \n",
       "3          0          0          0            0      1  \n",
       "4          0          0          0            0      1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OFzu-5f4N_6V"
   },
   "outputs": [],
   "source": [
    "feature = ['kdkc','dati2','typeppk','umur','jkpst']\n",
    "X = df[feature]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140151, 5) (60066, 5)\n",
      "(140151,) (60066,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)\n",
    "#printing the dimensions of each of those snapshots to see amount of rows and columns i each of them\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31245938,  0.85153619,  1.16963448,  0.26833667,  0.93062748],\n",
       "       [ 1.8321183 ,  0.39478483,  1.16963448,  1.26428256,  0.93062748],\n",
       "       [ 0.79106247,  0.52528522, -0.9099276 , -0.55440124,  0.93062748],\n",
       "       ...,\n",
       "       [-0.06402846, -0.23907419,  1.26866124,  0.09512869,  0.93062748],\n",
       "       [-0.22739949, -0.63057535,  1.16963448, -1.33383715, -1.07454381],\n",
       "       [ 0.29052144,  0.09649823,  1.16963448,  0.44154465,  0.93062748]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06402846, -0.23907419, -1.00895436,  0.22503468, -1.07454381],\n",
       "       [-1.47006212,  2.05400404,  1.26866124, -0.8575152 ,  0.93062748],\n",
       "       [-0.24130341, -0.5560037 ,  1.07060771,  0.48484665,  0.93062748],\n",
       "       ...,\n",
       "       [-0.25173135, -0.48143205,  1.07060771, -0.03477729,  0.93062748],\n",
       "       [ 0.78932448,  1.09389405,  1.16963448, -1.59364912, -1.07454381],\n",
       "       [-0.06055248, -0.08993089, -1.00895436,  0.83126261,  0.93062748]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(units=16, activation='relu'))\n",
    "classifier.add(Dense(units=16, activation='relu'))\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.6905 - accuracy: 0.5309 - val_loss: 0.6890 - val_accuracy: 0.5385\n",
      "Epoch 2/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6886 - accuracy: 0.5387 - val_loss: 0.6877 - val_accuracy: 0.5404\n",
      "Epoch 3/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6877 - accuracy: 0.5392 - val_loss: 0.6866 - val_accuracy: 0.5424\n",
      "Epoch 4/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6868 - accuracy: 0.5417 - val_loss: 0.6860 - val_accuracy: 0.5433\n",
      "Epoch 5/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6861 - accuracy: 0.5437 - val_loss: 0.6863 - val_accuracy: 0.5440\n",
      "Epoch 6/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6855 - accuracy: 0.5468 - val_loss: 0.6846 - val_accuracy: 0.5452\n",
      "Epoch 7/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6849 - accuracy: 0.5470 - val_loss: 0.6846 - val_accuracy: 0.5460\n",
      "Epoch 8/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6845 - accuracy: 0.5468 - val_loss: 0.6841 - val_accuracy: 0.5503\n",
      "Epoch 9/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6842 - accuracy: 0.5459 - val_loss: 0.6837 - val_accuracy: 0.5457\n",
      "Epoch 10/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6840 - accuracy: 0.5494 - val_loss: 0.6837 - val_accuracy: 0.5445\n",
      "Epoch 11/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6836 - accuracy: 0.5498 - val_loss: 0.6833 - val_accuracy: 0.5481\n",
      "Epoch 12/150\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.6833 - accuracy: 0.5497 - val_loss: 0.6829 - val_accuracy: 0.5499\n",
      "Epoch 13/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6830 - accuracy: 0.5503 - val_loss: 0.6831 - val_accuracy: 0.5448\n",
      "Epoch 14/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6827 - accuracy: 0.5512 - val_loss: 0.6837 - val_accuracy: 0.5485\n",
      "Epoch 15/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6825 - accuracy: 0.5522 - val_loss: 0.6817 - val_accuracy: 0.5513\n",
      "Epoch 16/150\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.6821 - accuracy: 0.5531 - val_loss: 0.6816 - val_accuracy: 0.5530\n",
      "Epoch 17/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6820 - accuracy: 0.5531 - val_loss: 0.6817 - val_accuracy: 0.5510\n",
      "Epoch 18/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6818 - accuracy: 0.5531 - val_loss: 0.6822 - val_accuracy: 0.5509\n",
      "Epoch 19/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6815 - accuracy: 0.5547 - val_loss: 0.6823 - val_accuracy: 0.5493\n",
      "Epoch 20/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6814 - accuracy: 0.5537 - val_loss: 0.6814 - val_accuracy: 0.5530\n",
      "Epoch 21/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6813 - accuracy: 0.5548 - val_loss: 0.6809 - val_accuracy: 0.5510\n",
      "Epoch 22/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6811 - accuracy: 0.5557 - val_loss: 0.6805 - val_accuracy: 0.5548\n",
      "Epoch 23/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6809 - accuracy: 0.5556 - val_loss: 0.6805 - val_accuracy: 0.5542\n",
      "Epoch 24/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6808 - accuracy: 0.5561 - val_loss: 0.6807 - val_accuracy: 0.5546\n",
      "Epoch 25/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6805 - accuracy: 0.5578 - val_loss: 0.6802 - val_accuracy: 0.5565\n",
      "Epoch 26/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6804 - accuracy: 0.5574 - val_loss: 0.6803 - val_accuracy: 0.5522\n",
      "Epoch 27/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6802 - accuracy: 0.5576 - val_loss: 0.6804 - val_accuracy: 0.5495\n",
      "Epoch 28/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6800 - accuracy: 0.5580 - val_loss: 0.6797 - val_accuracy: 0.5566\n",
      "Epoch 29/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5592 - val_loss: 0.6799 - val_accuracy: 0.5514\n",
      "Epoch 30/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.5586 - val_loss: 0.6795 - val_accuracy: 0.5546\n",
      "Epoch 31/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5569 - val_loss: 0.6798 - val_accuracy: 0.5578\n",
      "Epoch 32/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6798 - accuracy: 0.5573 - val_loss: 0.6801 - val_accuracy: 0.5580\n",
      "Epoch 33/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5586 - val_loss: 0.6793 - val_accuracy: 0.5573\n",
      "Epoch 34/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5589 - val_loss: 0.6790 - val_accuracy: 0.5562\n",
      "Epoch 35/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6795 - accuracy: 0.5591 - val_loss: 0.6790 - val_accuracy: 0.5535\n",
      "Epoch 36/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.5585 - val_loss: 0.6797 - val_accuracy: 0.5551\n",
      "Epoch 37/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6791 - accuracy: 0.5597 - val_loss: 0.6788 - val_accuracy: 0.5562\n",
      "Epoch 38/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6793 - accuracy: 0.5597 - val_loss: 0.6788 - val_accuracy: 0.5562\n",
      "Epoch 39/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5610 - val_loss: 0.6793 - val_accuracy: 0.5572\n",
      "Epoch 40/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6789 - accuracy: 0.5587 - val_loss: 0.6800 - val_accuracy: 0.5510\n",
      "Epoch 41/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6788 - accuracy: 0.5601 - val_loss: 0.6789 - val_accuracy: 0.5578\n",
      "Epoch 42/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6787 - accuracy: 0.5597 - val_loss: 0.6792 - val_accuracy: 0.5567\n",
      "Epoch 43/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6786 - accuracy: 0.5611 - val_loss: 0.6801 - val_accuracy: 0.5510\n",
      "Epoch 44/150\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.6784 - accuracy: 0.5607 - val_loss: 0.6792 - val_accuracy: 0.5585\n",
      "Epoch 45/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6783 - accuracy: 0.5599 - val_loss: 0.6781 - val_accuracy: 0.5571\n",
      "Epoch 46/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6781 - accuracy: 0.5614 - val_loss: 0.6791 - val_accuracy: 0.5527\n",
      "Epoch 47/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.5610 - val_loss: 0.6782 - val_accuracy: 0.5541\n",
      "Epoch 48/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5603 - val_loss: 0.6790 - val_accuracy: 0.5540\n",
      "Epoch 49/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6780 - accuracy: 0.5620 - val_loss: 0.6787 - val_accuracy: 0.5546\n",
      "Epoch 50/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5625 - val_loss: 0.6790 - val_accuracy: 0.5562\n",
      "Epoch 51/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5610 - val_loss: 0.6787 - val_accuracy: 0.5539\n",
      "Epoch 52/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6779 - accuracy: 0.5613 - val_loss: 0.6790 - val_accuracy: 0.5573\n",
      "Epoch 53/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6778 - accuracy: 0.5606 - val_loss: 0.6781 - val_accuracy: 0.5579\n",
      "Epoch 54/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5617 - val_loss: 0.6774 - val_accuracy: 0.5577\n",
      "Epoch 55/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5617 - val_loss: 0.6777 - val_accuracy: 0.5600\n",
      "Epoch 56/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6777 - accuracy: 0.5612 - val_loss: 0.6781 - val_accuracy: 0.5611\n",
      "Epoch 57/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5618 - val_loss: 0.6798 - val_accuracy: 0.5575\n",
      "Epoch 58/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6774 - accuracy: 0.5611 - val_loss: 0.6778 - val_accuracy: 0.5622\n",
      "Epoch 59/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5616 - val_loss: 0.6780 - val_accuracy: 0.5580\n",
      "Epoch 60/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6772 - accuracy: 0.5624 - val_loss: 0.6783 - val_accuracy: 0.5557\n",
      "Epoch 61/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6773 - accuracy: 0.5606 - val_loss: 0.6778 - val_accuracy: 0.5606\n",
      "Epoch 62/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6771 - accuracy: 0.5625 - val_loss: 0.6774 - val_accuracy: 0.5605\n",
      "Epoch 63/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6771 - accuracy: 0.5618 - val_loss: 0.6782 - val_accuracy: 0.5571\n",
      "Epoch 64/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6771 - accuracy: 0.5616 - val_loss: 0.6773 - val_accuracy: 0.5617\n",
      "Epoch 65/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6770 - accuracy: 0.5633 - val_loss: 0.6780 - val_accuracy: 0.5608\n",
      "Epoch 66/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6769 - accuracy: 0.5625 - val_loss: 0.6770 - val_accuracy: 0.5596\n",
      "Epoch 67/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6767 - accuracy: 0.5629 - val_loss: 0.6774 - val_accuracy: 0.5566\n",
      "Epoch 68/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6768 - accuracy: 0.5630 - val_loss: 0.6783 - val_accuracy: 0.5595\n",
      "Epoch 69/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6769 - accuracy: 0.5638 - val_loss: 0.6803 - val_accuracy: 0.5508\n",
      "Epoch 70/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6767 - accuracy: 0.5625 - val_loss: 0.6776 - val_accuracy: 0.5582\n",
      "Epoch 71/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6767 - accuracy: 0.5626 - val_loss: 0.6780 - val_accuracy: 0.5630\n",
      "Epoch 72/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6766 - accuracy: 0.5630 - val_loss: 0.6770 - val_accuracy: 0.5640\n",
      "Epoch 73/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6764 - accuracy: 0.5645 - val_loss: 0.6779 - val_accuracy: 0.5620\n",
      "Epoch 74/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6764 - accuracy: 0.5640 - val_loss: 0.6771 - val_accuracy: 0.5615\n",
      "Epoch 75/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6764 - accuracy: 0.5648 - val_loss: 0.6763 - val_accuracy: 0.5606\n",
      "Epoch 76/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6763 - accuracy: 0.5647 - val_loss: 0.6775 - val_accuracy: 0.5600\n",
      "Epoch 77/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6762 - accuracy: 0.5638 - val_loss: 0.6771 - val_accuracy: 0.5655\n",
      "Epoch 78/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6761 - accuracy: 0.5646 - val_loss: 0.6766 - val_accuracy: 0.5609\n",
      "Epoch 79/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6762 - accuracy: 0.5648 - val_loss: 0.6767 - val_accuracy: 0.5639\n",
      "Epoch 80/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6761 - accuracy: 0.5644 - val_loss: 0.6765 - val_accuracy: 0.5602\n",
      "Epoch 81/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6761 - accuracy: 0.5638 - val_loss: 0.6775 - val_accuracy: 0.5599\n",
      "Epoch 82/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6759 - accuracy: 0.5654 - val_loss: 0.6765 - val_accuracy: 0.5624\n",
      "Epoch 83/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6760 - accuracy: 0.5649 - val_loss: 0.6768 - val_accuracy: 0.5616\n",
      "Epoch 84/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6759 - accuracy: 0.5664 - val_loss: 0.6759 - val_accuracy: 0.5639\n",
      "Epoch 85/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6758 - accuracy: 0.5660 - val_loss: 0.6767 - val_accuracy: 0.5607\n",
      "Epoch 86/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6757 - accuracy: 0.5653 - val_loss: 0.6769 - val_accuracy: 0.5617\n",
      "Epoch 87/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6757 - accuracy: 0.5662 - val_loss: 0.6756 - val_accuracy: 0.5654\n",
      "Epoch 88/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6757 - accuracy: 0.5651 - val_loss: 0.6758 - val_accuracy: 0.5645\n",
      "Epoch 89/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6756 - accuracy: 0.5669 - val_loss: 0.6768 - val_accuracy: 0.5593\n",
      "Epoch 90/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6755 - accuracy: 0.5662 - val_loss: 0.6759 - val_accuracy: 0.5643\n",
      "Epoch 91/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6756 - accuracy: 0.5668 - val_loss: 0.6754 - val_accuracy: 0.5663\n",
      "Epoch 92/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6755 - accuracy: 0.5654 - val_loss: 0.6763 - val_accuracy: 0.5657\n",
      "Epoch 93/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6754 - accuracy: 0.5659 - val_loss: 0.6776 - val_accuracy: 0.5599\n",
      "Epoch 94/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6754 - accuracy: 0.5664 - val_loss: 0.6752 - val_accuracy: 0.5676\n",
      "Epoch 95/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6753 - accuracy: 0.5663 - val_loss: 0.6758 - val_accuracy: 0.5619\n",
      "Epoch 96/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6754 - accuracy: 0.5671 - val_loss: 0.6756 - val_accuracy: 0.5645\n",
      "Epoch 97/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6754 - accuracy: 0.5666 - val_loss: 0.6751 - val_accuracy: 0.5676\n",
      "Epoch 98/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6752 - accuracy: 0.5683 - val_loss: 0.6750 - val_accuracy: 0.5665\n",
      "Epoch 99/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6750 - accuracy: 0.5682 - val_loss: 0.6764 - val_accuracy: 0.5644\n",
      "Epoch 100/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6752 - accuracy: 0.5678 - val_loss: 0.6750 - val_accuracy: 0.5657\n",
      "Epoch 101/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6751 - accuracy: 0.5680 - val_loss: 0.6750 - val_accuracy: 0.5643\n",
      "Epoch 102/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6751 - accuracy: 0.5675 - val_loss: 0.6755 - val_accuracy: 0.5608\n",
      "Epoch 103/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6749 - accuracy: 0.5679 - val_loss: 0.6747 - val_accuracy: 0.5725\n",
      "Epoch 104/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6752 - accuracy: 0.5678 - val_loss: 0.6759 - val_accuracy: 0.5642\n",
      "Epoch 105/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6750 - accuracy: 0.5679 - val_loss: 0.6748 - val_accuracy: 0.5649\n",
      "Epoch 106/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6749 - accuracy: 0.5692 - val_loss: 0.6747 - val_accuracy: 0.5680\n",
      "Epoch 107/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6747 - accuracy: 0.5685 - val_loss: 0.6755 - val_accuracy: 0.5676\n",
      "Epoch 108/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6748 - accuracy: 0.5682 - val_loss: 0.6759 - val_accuracy: 0.5623\n",
      "Epoch 109/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6747 - accuracy: 0.5684 - val_loss: 0.6764 - val_accuracy: 0.5660\n",
      "Epoch 110/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6748 - accuracy: 0.5668 - val_loss: 0.6760 - val_accuracy: 0.5629\n",
      "Epoch 111/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6747 - accuracy: 0.5675 - val_loss: 0.6760 - val_accuracy: 0.5610\n",
      "Epoch 112/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6746 - accuracy: 0.5692 - val_loss: 0.6753 - val_accuracy: 0.5622\n",
      "Epoch 113/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6747 - accuracy: 0.5674 - val_loss: 0.6746 - val_accuracy: 0.5655\n",
      "Epoch 114/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6744 - accuracy: 0.5695 - val_loss: 0.6752 - val_accuracy: 0.5669\n",
      "Epoch 115/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6746 - accuracy: 0.5698 - val_loss: 0.6750 - val_accuracy: 0.5651\n",
      "Epoch 116/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6746 - accuracy: 0.5679 - val_loss: 0.6749 - val_accuracy: 0.5694\n",
      "Epoch 117/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6745 - accuracy: 0.5681 - val_loss: 0.6750 - val_accuracy: 0.5643\n",
      "Epoch 118/150\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.6744 - accuracy: 0.5694 - val_loss: 0.6751 - val_accuracy: 0.5651\n",
      "Epoch 119/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6744 - accuracy: 0.5692 - val_loss: 0.6746 - val_accuracy: 0.5687\n",
      "Epoch 120/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6743 - accuracy: 0.5694 - val_loss: 0.6746 - val_accuracy: 0.5689\n",
      "Epoch 121/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6744 - accuracy: 0.5693 - val_loss: 0.6742 - val_accuracy: 0.5672\n",
      "Epoch 122/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6744 - accuracy: 0.5689 - val_loss: 0.6748 - val_accuracy: 0.5646\n",
      "Epoch 123/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6743 - accuracy: 0.5685 - val_loss: 0.6745 - val_accuracy: 0.5656\n",
      "Epoch 124/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6741 - accuracy: 0.5699 - val_loss: 0.6750 - val_accuracy: 0.5656\n",
      "Epoch 125/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6740 - accuracy: 0.5700 - val_loss: 0.6747 - val_accuracy: 0.5631\n",
      "Epoch 126/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6741 - accuracy: 0.5698 - val_loss: 0.6737 - val_accuracy: 0.5694\n",
      "Epoch 127/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6741 - accuracy: 0.5700 - val_loss: 0.6748 - val_accuracy: 0.5654\n",
      "Epoch 128/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6739 - accuracy: 0.5693 - val_loss: 0.6739 - val_accuracy: 0.5677\n",
      "Epoch 129/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6740 - accuracy: 0.5700 - val_loss: 0.6741 - val_accuracy: 0.5653\n",
      "Epoch 130/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6738 - accuracy: 0.5710 - val_loss: 0.6740 - val_accuracy: 0.5683\n",
      "Epoch 131/150\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.6738 - accuracy: 0.5692 - val_loss: 0.6738 - val_accuracy: 0.5700\n",
      "Epoch 132/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6737 - accuracy: 0.5703 - val_loss: 0.6735 - val_accuracy: 0.5716\n",
      "Epoch 133/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6737 - accuracy: 0.5714 - val_loss: 0.6745 - val_accuracy: 0.5659\n",
      "Epoch 134/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6737 - accuracy: 0.5702 - val_loss: 0.6744 - val_accuracy: 0.5694\n",
      "Epoch 135/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6734 - accuracy: 0.5705 - val_loss: 0.6748 - val_accuracy: 0.5673\n",
      "Epoch 136/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6735 - accuracy: 0.5708 - val_loss: 0.6735 - val_accuracy: 0.5698\n",
      "Epoch 137/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6735 - accuracy: 0.5703 - val_loss: 0.6744 - val_accuracy: 0.5656\n",
      "Epoch 138/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6735 - accuracy: 0.5694 - val_loss: 0.6736 - val_accuracy: 0.5710\n",
      "Epoch 139/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6734 - accuracy: 0.5711 - val_loss: 0.6736 - val_accuracy: 0.5721\n",
      "Epoch 140/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6734 - accuracy: 0.5712 - val_loss: 0.6733 - val_accuracy: 0.5744\n",
      "Epoch 141/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6733 - accuracy: 0.5723 - val_loss: 0.6734 - val_accuracy: 0.5727\n",
      "Epoch 142/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6732 - accuracy: 0.5720 - val_loss: 0.6743 - val_accuracy: 0.5706\n",
      "Epoch 143/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6732 - accuracy: 0.5708 - val_loss: 0.6736 - val_accuracy: 0.5727\n",
      "Epoch 144/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6731 - accuracy: 0.5719 - val_loss: 0.6741 - val_accuracy: 0.5666\n",
      "Epoch 145/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6733 - accuracy: 0.5721 - val_loss: 0.6736 - val_accuracy: 0.5732\n",
      "Epoch 146/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6731 - accuracy: 0.5720 - val_loss: 0.6732 - val_accuracy: 0.5728\n",
      "Epoch 147/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6733 - accuracy: 0.5716 - val_loss: 0.6743 - val_accuracy: 0.5678\n",
      "Epoch 148/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6731 - accuracy: 0.5710 - val_loss: 0.6744 - val_accuracy: 0.5645\n",
      "Epoch 149/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6732 - accuracy: 0.5713 - val_loss: 0.6741 - val_accuracy: 0.5701\n",
      "Epoch 150/150\n",
      "1122/1122 [==============================] - 2s 2ms/step - loss: 0.6729 - accuracy: 0.5718 - val_loss: 0.6729 - val_accuracy: 0.5723\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train, batch_size=100, epochs=150, validation_split=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_accuracy: 56.01%\n"
     ]
    }
   ],
   "source": [
    "#akurasi validasi\n",
    "val_accuracy = np.mean(history.history['val_accuracy'])\n",
    "print(\"\\n%s: %.2f%%\" % ('val_accuracy', val_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1878/1878 [==============================] - 2s 1ms/step - loss: 0.6725 - accuracy: 0.5733\n",
      "[0.6725431680679321, 0.5733360052108765]\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4380/4380 [==============================] - 5s 1ms/step\n",
      "1878/1878 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = classifier.predict(X_train)\n",
    "y_train_pred = (y_train_pred > 0.5)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "y_test_pred = (y_test_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.57     69928\n",
      "           1       0.58      0.57      0.57     70223\n",
      "\n",
      "    accuracy                           0.57    140151\n",
      "   macro avg       0.57      0.57      0.57    140151\n",
      "weighted avg       0.57      0.57      0.57    140151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2022-12-13 17:19:25         1789\n",
      "metadata.json                                  2022-12-13 17:19:25           64\n",
      "variables.h5                                   2022-12-13 17:19:25        27456\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(classifier, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ljrxg00k0O8Z",
    "H2DYqnnE138G",
    "mcEQf9h31ww8",
    "jXBZwZjl1sWW",
    "ioSwM_ry1rWI",
    "_oZ3IwnV1lST",
    "MwBHUx6n1YaO",
    "JrM2OHL91c5q",
    "cIGpZGIvzOts",
    "5zHJC-n8zT7h",
    "_-YniPTIzajh",
    "q8bR--kxzmen",
    "Y_askkW8zu-z"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9353014ca763536a03fddf2b7ff816e72186a35f4e9d7de87bb0d43b74d3ae7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
